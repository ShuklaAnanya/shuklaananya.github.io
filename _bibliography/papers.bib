---
---

@inproceedings{shukla2026obscuration,
  abbr={ISBI 2026},
  title={Obscuration to Clarity: Bone Suppression for Enhanced Localization in Pneumothorax Segmentation of Chest Radiographs},
  author={Shukla, Ananya and Rao, Amog and Siddharth, S and Bao, Rina},
  booktitle={2026 IEEE 23rd International Symposium on Biomedical Imaging (ISBI)},
  year={2026},
  organization={IEEE Computer Society},
  bibtex_show={true},
  selected={true},
  abstract={Chest radiography (CXR) is a primary modality for assessing cardiopulmonary conditions, but its effectiveness is limited by anatomical obstructions (e.g., ribs, clavicles) that hinder accurate pneumothorax segmentation, boundary delineation, and severity estimation. While deep learning-based bone suppression improves soft-tissue visibility, its utility for precise pixel-wise localization remains underexplored. This study investigates the downstream application of bone suppression for pneumothorax segmentation, integrating it as a pre-processing step to mitigate bony obscuration. We evaluate its impact across CNN and Vision Transformer models on two public datasets, where models trained on bone-suppressed CXRs significantly outperform (p<0.05) non-suppressed counterparts, achieving up to 17% improvement in Mean Average Surface Distance (MASD), 4.9% in Dice Similarity Coefficient (DSC), and 5.9% in Normalized Surface Dice (NSD), alongside a 9.5% gain in Matthew's Correlation Coefficient (MCC). These results demonstrate bone suppression as an architecture-independent enhancement for pneumothorax localization, improving the reliability of automated CXR interpretation.}
}

@inproceedings{shukla2026guideai,
  abbr={IUI 2026},
  title={GuideAI: A Real-time Personalized Learning Solution with Adaptive Interventions},
  author={Shukla, Ananya and Bajpai, Satvik and Modi, Chaitanya and Siddharth, S},
  booktitle={Proceedings of the 31st International Conference on Intelligent User Interfaces (IUI '26)},
  year={2026},
  organization={Association for Computing Machinery},
  address={New York, NY, USA},
  bibtex_show={true},
  selected={true},
  abstract={Large Language Models (LLMs) have emerged as powerful learning tools, but they lack awareness of learners' cognitive and physiological states, limiting their adaptability to the user's learning style. Contemporary learning techniques primarily focus on structured learning paths, knowledge tracing, and generic adaptive testing but fail to address real-time learning challenges driven by cognitive load, attention fluctuations, and engagement levels. Building on findings from a formative user study (N = 66), we introduce GuideAI, a multi-modal framework that enhances LLM-driven learning by integrating real-time biosensory feedback including eye gaze tracking, heart rate variability, posture detection, and digital note-taking behavior. GuideAI dynamically adapts learning content and pacing through cognitive optimizations (adjusting complexity based on learning progress markers), physiological interventions (breathing guidance and posture correction), and attention-aware strategies (redirecting focus using gaze analysis). Additionally, GuideAI supports diverse learning modalities, including text-based, image-based, audio-based, and video-based instruction, across varied knowledge domains. A preliminary study (N = 25) assessed GuideAI's impact on knowledge retention and cognitive load through standardized assessments. The results show statistically significant improvements in both problem-solving capability and recall-based knowledge assessments. Participants also experienced notable reductions in key NASA-TLX measures including mental demand, frustration levels, and effort, while simultaneously reporting enhanced perceived performance. These findings demonstrate GuideAI's potential to bridge the gap between current LLM-based learning systems and individualized learner needs, paving the way for adaptive, cognition-aware education at scale.},
  pdf={https://arxiv.org/abs/2601.20402}
}

@inproceedings{rao2025spatial,
  abbr={MICCAI 2025},
  title={Spatial Prior-Guided Boundary and Region-Aware 2D Lesion Segmentation in Neonatal Hypoxic Ischemic Encephalopathy},
  author={Rao, Amog and Shukla, Ananya and Bhargava, Jia and Ou, Yangming and Bao, Rina},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={520--530},
  year={2025},
  organization={Springer},
  bibtex_show={true},
  selected={true},
  abstract={Segmenting acute and hyper-acute brain lesions in neonatal hypoxic ischemic encephalopathy (HIE) from diffusion-weighted MRI (DWI) is critical for prognosis and treatment planning but remains challenging due to severe class imbalance and lesion variability. We propose a computationally efficient 2D segmentation framework leveraging ADC and ZADC maps as a three-channel input to UNet++ with an Inception-v4 encoder and scSE attention for enhanced spatial-channel recalibration. To address critical class imbalance and lack of volumetric context in 2D methods, we introduce a novel boundary-and-region-aware weighted loss integrating Tversky, Log-Hausdorff, and Focal losses. Our method surpasses state-of-the-art 2D approaches and achieves competitive performance against computationally intensive 3D architectures, securing a DSC of 0.6060, MASD of 2.6484, and NSD of 0.7477. These results establish a new benchmark for neonatal HIE lesion segmentation, demonstrating superior detection of both acute and hyper-acute lesions while mitigating the challenge of loss collapse.},
  pdf={https://link.springer.com/chapter/10.1007/978-3-032-04965-0_49}
}

@article{galeazzi2025fastconformation,
  abbr={bioRxiv},
  title={FastConformation: A Standalone ML-Based Toolkit for Modeling and Analyzing Protein Conformational Ensembles at Scale},
  author={Galeazzi, Flavia Maria and da Silva, Gabriel Monteiro and Arantes, Pablo and Varghese, Iz and Shukla, Ananya and Rubenstein, Brenda M},
  journal={bioRxiv},
  year={2025},
  bibtex_show={true},
  abstract={Deep learning approaches like AlphaFold 2 (AF2) have revolutionized structural biology by accurately predicting the ground state structures of proteins. Recently, clustering and subsampling techniques that manipulate multiple sequence alignment (MSA) inputs into AlphaFold to generate conformational ensembles of proteins have also been proposed. Although many of these techniques have been made open source, they often require integrating multiple packages and can be challenging for researchers who have a limited programming background to employ. This is especially true when researchers are interested in subsampling to produce predictions of protein conformational ensembles, which require multiple computational steps. This manuscript introduces FastConformation, a Python-based application that integrates MSA generation, structure prediction via AF2, and interactive analysis of protein conformations and their distributions, all in one place. FastConformation is accessible through a user-friendly GUI suitable for non-programmers, allowing users to iteratively refine subsampling parameters based on their analyses to achieve diverse conformational ensembles. Starting from an amino acid sequence, users can make protein conformation predictions and analyze results in just a few hours on their local machines, which is significantly faster than traditional molecular dynamics (MD) simulations. Uniquely, by leveraging the subsampling of MSAs, our tool enables the generation of alternative protein conformations. We demonstrate the utility of FastConformation on proteins including the Abl1 kinase, LAT1 transporter, and CCR5 receptor, showcasing its ability to predict and analyze the protein conformational ensembles and effects of mutations on a variety of proteins. This tool enables a wide range of high-throughput applications in protein biochemistry, drug discovery, and protein engineering.},
  pdf={https://pmc.ncbi.nlm.nih.gov/articles/PMC12132556/}
}